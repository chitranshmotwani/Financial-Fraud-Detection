{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Valuation for Fraud Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load processed data\n",
    "X_train, X_test, y_train, y_test = joblib.load('data/processed/processed_data.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-One-Out Influence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use a subset for this analysis due to computational constraints\n",
    "sample_idx = np.random.choice(X_train.index, size=1000, replace=False)\n",
    "X_sample = X_train.loc[sample_idx]\n",
    "y_sample = y_train.loc[sample_idx]\n",
    "\n",
    "# Train base model on full sample\n",
    "base_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "base_model.fit(X_sample, y_sample)\n",
    "base_score = roc_auc_score(y_test, base_model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# Calculate leave-one-out influences\n",
    "influences = []\n",
    "\n",
    "for idx in tqdm(sample_idx):\n",
    "    # Train model without this instance\n",
    "    X_loo = X_sample.drop(idx)\n",
    "    y_loo = y_sample.drop(idx)\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_loo, y_loo)\n",
    "    \n",
    "    # Calculate score difference\n",
    "    score = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    influence = base_score - score\n",
    "    influences.append(influence)\n",
    "\n",
    "# Add to dataframe\n",
    "influence_df = pd.DataFrame({\n",
    "    'index': sample_idx,\n",
    "    'influence': influences,\n",
    "    'class': y_sample\n",
    "})\n",
    "\n",
    "# Save results\n",
    "influence_df.to_csv('data/processed/loo_influence.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence Analysis Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of influences\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=influence_df, x='influence', hue='class', bins=50)\n",
    "plt.title('Distribution of Instance Influences by Class')\n",
    "plt.xlabel('Influence (Change in ROC-AUC when removed)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Influential Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top positive influences (instances that hurt performance when removed)\n",
    "print(\"Top Positive Influences (Important instances):\")\n",
    "print(influence_df.sort_values('influence', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Valuation with KNN Shapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified KNN-Shapley approximation\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# We'll use a smaller subset for this\n",
    "knn_sample_idx = np.random.choice(X_train.index, size=500, replace=False)\n",
    "X_knn = X_train.loc[knn_sample_idx]\n",
    "y_knn = y_train.loc[knn_sample_idx]\n",
    "\n",
    "# Train KNN model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_knn, y_knn)\n",
    "\n",
    "# Get nearest neighbors for test instances\n",
    "test_probas = knn.predict_proba(X_test)\n",
    "test_preds = (test_probas[:, 1] > 0.5).astype(int)\n",
    "\n",
    "# Calculate marginal contributions\n",
    "shapley_values = np.zeros(len(X_knn))\n",
    "\n",
    "for i, (idx, row) in enumerate(X_knn.iterrows()):\n",
    "    # Remove this instance\n",
    "    X_minus_i = X_knn.drop(idx)\n",
    "    y_minus_i = y_knn.drop(idx)\n",
    "    \n",
    "    # Retrain without this instance\n",
    "    knn_minus_i = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn_minus_i.fit(X_minus_i, y_minus_i)\n",
    "    \n",
    "    # Calculate difference in predictions\n",
    "    probas_minus_i = knn_minus_i.predict_proba(X_test)\n",
    "    preds_minus_i = (probas_minus_i[:, 1] > 0.5).astype(int)\n",
    "    \n",
    "    # Marginal contribution is accuracy difference\n",
    "    acc_full = (test_preds == y_test).mean()\n",
    "    acc_minus_i = (preds_minus_i == y_test).mean()\n",
    "    shapley_values[i] = acc_full - acc_minus_i\n",
    "\n",
    "# Add to dataframe\n",
    "shapley_df = pd.DataFrame({\n",
    "    'index': X_knn.index,\n",
    "    'shapley_value': shapley_values,\n",
    "    'class': y_knn\n",
    "})\n",
    "\n",
    "# Save results\n",
    "shapley_df.to_csv('data/processed/knn_shapley.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shapley Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of Shapley values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=shapley_df, x='shapley_value', hue='class', bins=50)\n",
    "plt.title('Distribution of Shapley Values by Class')\n",
    "plt.xlabel('Shapley Value')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Valuable Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top instances by Shapley value\n",
    "print(\"Top Valuable Instances:\")\n",
    "print(shapley_df.sort_values('shapley_value', ascending=False).head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
